# ğŸ§  Ollama Chatbot Microservice with Service Discovery

A **microservices-based chatbot** using **Flask** and **Ollama**, integrated with a **dynamic service discovery system** to enable seamless communication between services.

---

## ğŸ“Œ Features
- âœ… **Service Discovery** - Services dynamically register, send heartbeats, and communicate without hardcoded addresses.
- âœ… **Ollama AI Processing** - Chatbot uses **Llama 3.2** for AI-generated responses.
- âœ… **Automatic Cleanup** - Inactive services are removed after **5 minutes**.
- âœ… **Message Forwarding** - Microservices can send messages to each other.

---

## ğŸ“‚ Project Structure

```
 Service-Discovery/         # Service discovery system
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ service_discovery_controller.py  # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ service_discovery_service.py  # Core logic (service registry)
â”‚   â”‚   â”œâ”€â”€ main.py  # Runs the service discovery system
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ venv/
â”‚
â”‚â”€â”€ ollama_chatbot/            # AI Chatbot microservice
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py  # Handles registration, AI processing
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ venv/
â”‚
â”‚â”€â”€ README.md
```

---

## ğŸ› ï¸ Pre-requisites

### ğŸ”¹ 1. Install Ollama
Ollama is required for AI processing. Install it using the following steps:

**Linux & macOS:**
```sh
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
Download and install from [Ollama Official Website](https://ollama.ai/).

Ensure Ollama is running:
```sh
ollama serve &
```

### ğŸ”¹ 2. Install Python & Virtual Environment
Ensure Python 3.8+ is installed:
```sh
python --version
```
If not installed, download it from [Python Official Website](https://www.python.org/downloads/).

---

## ğŸ› ï¸ Installation & Setup

### ğŸ”¹ 1. Clone the Repository
```sh
git clone https://github.com/htbalar/Service-Discovery.git
cd Service-Discovery
```

### ğŸ”¹ 2. Install Dependencies

For **Service Discovery**:
```sh
cd Service-Discovery
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
deactivate
cd ..
```

For **Ollama Chatbot**:
```sh
cd ollama_chatbot
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
deactivate
cd ..
```

---

## ğŸš€ Running the Microservices

### 1ï¸âƒ£ **Start the Service Discovery System** (Runs on port **5000**)
```sh
cd Service-Discovery
source venv/bin/activate
python app/main.py
```

### 2ï¸âƒ£ **Start the Ollama Chatbot Microservice** (Runs on port **5001**)
```sh
cd ollama_chatbot
source venv/bin/activate
python app/main.py ollama_chatbot 5001
```

---

## ğŸ§ª Testing API Calls

### âœ… **Check Registered Services**
```sh
curl -X GET http://localhost:5000/service-discovery/services
```

### âœ… **Send a Prompt to the Chatbot**
```sh
curl -X POST http://localhost:5001/process \
     -H "Content-Type: application/json" \
     -d '{"prompt": "What is AI?"}'
```

---

## ğŸ”„ Stopping the Services

To **stop** all running services, press `CTRL + C` in each terminal.

---

## ğŸ¯ Summary

| **Task**  | **Command**  |
|-------------------|-------------|
| Install dependencies  | `pip install -r requirements.txt`  |
| Run Service Discovery | `python app/main.py` (Port **5000**) |
| Run Ollama Chatbot | `python app/main.py ollama_chatbot 5001` (Port **5001**) |
| Get Services List | `curl -X GET http://localhost:5000/service-discovery/services` |
| Forward Message | `curl -X POST http://localhost:5000/service-discovery/forward` |
| Stop Everything | `CTRL + C`  |

---

## ğŸ“ Contributing

1ï¸âƒ£ **Fork the repository**
2ï¸âƒ£ **Create a feature branch** (`git checkout -b feature-name`)
3ï¸âƒ£ **Commit your changes** (`git commit -m "Added new feature"`)
4ï¸âƒ£ **Push to GitHub** (`git push origin feature-name`)
5ï¸âƒ£ **Create a Pull Request (PR)** ğŸš€

---
